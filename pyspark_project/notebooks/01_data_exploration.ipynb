{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "762a760d",
   "metadata": {},
   "source": [
    "# üè• Healthcare Data Exploration with PySpark\n",
    "\n",
    "This notebook demonstrates loading and exploring Synthea synthetic patient data from Google BigQuery using PySpark.\n",
    "\n",
    "**Dataset:** CMS Synthetic Patient Data (OMOP format)  \n",
    "**Source:** `bigquery-public-data.cms_synthetic_patient_data_omop`  \n",
    "**Size:** 1M+ synthetic patients, ~10GB\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54760d7f",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95aa45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # Add src to path\n",
    "\n",
    "from src.utils.spark_session import get_spark_session\n",
    "from src.data_ingestion.bigquery_loader import BigQueryLoader\n",
    "\n",
    "# Create Spark session\n",
    "spark = get_spark_session(\n",
    "    app_name=\"HealthcareDataExploration\",\n",
    "    local=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Spark {spark.version} initialized\")\n",
    "print(f\"üìä Spark UI: {spark.sparkContext.uiWebUrl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e714da22",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Load Patient Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe882af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BigQuery loader\n",
    "loader = BigQueryLoader(\n",
    "    spark=spark,\n",
    "    gcp_project=\"your-project-id\"  # CHANGE THIS\n",
    ")\n",
    "\n",
    "# Load sample patients (limit for exploration)\n",
    "patients_df = loader.load_patients(limit=10000)\n",
    "\n",
    "print(f\"\\nüìä Loaded {patients_df.count():,} patients\")\n",
    "print(f\"üìã Columns: {len(patients_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6772a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display schema\n",
    "patients_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadc36d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample records\n",
    "patients_df.select(\n",
    "    \"person_id\",\n",
    "    \"gender_concept_id\",\n",
    "    \"year_of_birth\",\n",
    "    \"race_concept_id\",\n",
    "    \"ethnicity_concept_id\",\n",
    "    \"age\"\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8067fbb4",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Age distribution\n",
    "print(\"üìä Age Distribution:\")\n",
    "patients_df.select(\n",
    "    F.min(\"age\").alias(\"min_age\"),\n",
    "    F.max(\"age\").alias(\"max_age\"),\n",
    "    F.avg(\"age\").alias(\"avg_age\"),\n",
    "    F.stddev(\"age\").alias(\"std_age\")\n",
    ").show()\n",
    "\n",
    "# Age groups\n",
    "print(\"\\nüìä Age Groups:\")\n",
    "patients_df \\\n",
    "    .withColumn(\"age_group\", \n",
    "        F.when(F.col(\"age\") < 18, \"0-17\")\n",
    "         .when(F.col(\"age\") < 35, \"18-34\")\n",
    "         .when(F.col(\"age\") < 50, \"35-49\")\n",
    "         .when(F.col(\"age\") < 65, \"50-64\")\n",
    "         .otherwise(\"65+\")\n",
    "    ) \\\n",
    "    .groupBy(\"age_group\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"age_group\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96827a6",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Load Hospital Encounters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecfea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load encounters (hospital visits)\n",
    "encounters_df = loader.load_encounters(\n",
    "    limit=50000,\n",
    "    start_date=\"2020-01-01\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Loaded {encounters_df.count():,} encounters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dedac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show encounters\n",
    "encounters_df.select(\n",
    "    \"visit_occurrence_id\",\n",
    "    \"person_id\",\n",
    "    \"visit_start_date\",\n",
    "    \"visit_end_date\",\n",
    "    \"length_of_stay_days\"\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497e9103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of stay statistics\n",
    "print(\"üìä Length of Stay Statistics:\")\n",
    "encounters_df.select(\n",
    "    F.min(\"length_of_stay_days\").alias(\"min_los\"),\n",
    "    F.max(\"length_of_stay_days\").alias(\"max_los\"),\n",
    "    F.avg(\"length_of_stay_days\").alias(\"avg_los\"),\n",
    "    F.percentile_approx(\"length_of_stay_days\", 0.5).alias(\"median_los\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da50e7b4",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Join Patients and Encounters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cc844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join patients with their encounters\n",
    "patient_encounters = patients_df.join(\n",
    "    encounters_df,\n",
    "    on=\"person_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(f\"üìä Joined DataFrame: {patient_encounters.count():,} rows\")\n",
    "\n",
    "# Show combined data\n",
    "patient_encounters.select(\n",
    "    \"person_id\",\n",
    "    \"age\",\n",
    "    \"gender_concept_id\",\n",
    "    \"visit_start_date\",\n",
    "    \"length_of_stay_days\"\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc75dd2",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Aggregations by Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e4260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate per-patient statistics\n",
    "patient_stats = patient_encounters.groupBy(\"person_id\", \"age\") \\\n",
    "    .agg(\n",
    "        F.count(\"visit_occurrence_id\").alias(\"total_visits\"),\n",
    "        F.sum(\"length_of_stay_days\").alias(\"total_los\"),\n",
    "        F.avg(\"length_of_stay_days\").alias(\"avg_los\"),\n",
    "        F.min(\"visit_start_date\").alias(\"first_visit\"),\n",
    "        F.max(\"visit_start_date\").alias(\"last_visit\")\n",
    "    )\n",
    "\n",
    "patient_stats.orderBy(F.desc(\"total_visits\")).show(10)\n",
    "\n",
    "print(f\"\\nüìä Patients with encounters: {patient_stats.count():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b26354f",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ High Utilizers Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4000770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find high utilizers (many hospital visits)\n",
    "high_utilizers = patient_stats.filter(F.col(\"total_visits\") >= 5)\n",
    "\n",
    "print(f\"üö® High Utilizers (5+ visits): {high_utilizers.count():,} patients\")\n",
    "print(f\"   Percentage: {high_utilizers.count() / patient_stats.count() * 100:.1f}%\")\n",
    "\n",
    "# Show top utilizers\n",
    "high_utilizers.orderBy(F.desc(\"total_visits\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1568332a",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Visualization (Convert to Pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a85e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert small aggregated data to Pandas for plotting\n",
    "visit_counts = patient_stats.groupBy(\"total_visits\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"total_visits\") \\\n",
    "    .limit(20) \\\n",
    "    .toPandas()\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(visit_counts['total_visits'], visit_counts['count'])\n",
    "plt.xlabel('Number of Visits')\n",
    "plt.ylabel('Number of Patients')\n",
    "plt.title('Distribution of Hospital Visits per Patient')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "age_stats = patients_df.groupBy(\"age\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"age\") \\\n",
    "    .toPandas()\n",
    "plt.plot(age_stats['age'], age_stats['count'])\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Number of Patients')\n",
    "plt.title('Patient Age Distribution')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1c341a",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32634d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to local parquet (for later use)\n",
    "output_path = \"../data/processed/patient_stats.parquet\"\n",
    "\n",
    "patient_stats.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(output_path)\n",
    "\n",
    "print(f\"‚úÖ Saved patient statistics to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fd2593",
   "metadata": {},
   "source": [
    "## üéØ Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. ‚úÖ Created PySpark session with BigQuery connector\n",
    "2. ‚úÖ Loaded synthetic patient data (10,000 patients)\n",
    "3. ‚úÖ Loaded hospital encounters (50,000 visits)\n",
    "4. ‚úÖ Performed basic exploratory analysis\n",
    "5. ‚úÖ Joined datasets using PySpark SQL\n",
    "6. ‚úÖ Calculated per-patient aggregations\n",
    "7. ‚úÖ Identified high utilizers\n",
    "8. ‚úÖ Visualized results with Matplotlib\n",
    "9. ‚úÖ Saved processed data to Parquet\n",
    "\n",
    "**Next Steps:**\n",
    "- Explore conditions, procedures, medications\n",
    "- Feature engineering for ML models\n",
    "- Build readmission prediction model\n",
    "- Deploy to GCP Dataproc cluster\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e3915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "spark.stop()\n",
    "print(\"üõë Spark session stopped\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
